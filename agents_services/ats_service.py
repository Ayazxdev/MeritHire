"""
ATS Fraud Detection Service
FastAPI service that wraps the ATS fraud detection agent.
Port: 8004
"""
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional
import sys
import os
import logging

import re
from collections import Counter
from contextlib import asynccontextmanager
import requests

# Add agents path to sys.path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'agents_files', 'Clean_Hiring_System'))
# Also add skill_verification_agent to path for utils imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'agents_files', 'Clean_Hiring_System', 'skill_verification_agent'))

# Pre-import detector modules so they're cached when ats.py tries to import them
try:
    from utils.pdf_layer_extractor import WhiteTextDetector
    from utils.manipulation_detector import PromptInjectionDefender
    from utils.image_text_extractor import ImageInjectionDetector
    from utils.evasion_detector import SophisticatedEvasionDetector
except ImportError as e:
    logging.warning(f"Some detectors not available: {e}")

# app = FastAPI redefined below with lifespan
logger = logging.getLogger("uvicorn.error")

# Global agent instance
ats_agent = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Lifespan manager for ATS service"""
    global ats_agent
    try:
        from skill_verification_agent.agents.ats import ATSEvidenceAgent
        ats_agent = ATSEvidenceAgent(llm=None)
        logger.info("ATS Agent initialized successfully")
        
        # Check Ollama health
        try:
            resp = requests.get("http://localhost:11434/api/tags", timeout=2)
            if resp.status_code == 200:
                logger.info("✅ Local Ollama detected. ATS will use LLM extraction.")
            else:
                logger.warning("⚠️ Local Ollama unreachable. ATS will fallback to FAST regex extraction.")
        except:
            logger.warning("⚠️ Local Ollama not running. ATS will fallback to FAST regex extraction.")
            
    except Exception as e:
        logger.error(f"Failed to initialize ATS agent: {str(e)}")
    yield

app = FastAPI(title="ATS Fraud Detection Service", lifespan=lifespan, version="1.0.0")


class ATSRequest(BaseModel):
    application_id: Optional[int] = None
    resume_text: str
    resume_path: Optional[str] = None

class ATSResponse(BaseModel):
    action: str  # "OK" | "NEEDS_REVIEW" | "BLACKLIST"
    status: Optional[str] = None # For compatibility
    fraud_detected: Optional[bool] = None
    needs_review: Optional[bool] = None
    reason: Optional[str] = None
    severity: str = "none"
    flags: list = []
    analysis: dict = {}
    manipulation_signals: Optional[dict] = None
    evidence: Optional[dict] = None


@app.post("/run", response_model=ATSResponse)
@app.post("/analyze", response_model=ATSResponse)
async def analyze_resume(request: ATSRequest):
    """
    Analyze resume for fraud and manipulation attempts
    """
    global ats_agent
    
    try:
        flags = []
        severity = "none"
        reason = None
        action = "OK"
        text = request.resume_text

        # 1. Real-time patterns from Claude's integration
        # White text (hidden keywords)
        suspicious_chars = ['\u200b', '\u200c', '\u200d', '\ufeff']
        white_text_count = sum(text.count(char) for char in suspicious_chars)
        if white_text_count > 10:
            flags.append("white_text_detected")
            severity = "high"
            reason = "Potential white text manipulation detected"
        
        # Prompt injection
        prompt_injection_patterns = [
            r'ignore\s+(previous|all|above)\s+instructions',
            r'system\s*:\s*you\s+are',
            r'act\s+as\s+a',
            r'pretend\s+to\s+be',
            r'<\|im_start\|>',
            r'<\|im_end\|>',
            r'\[INST\]',
            r'\[\/INST\]'
        ]
        for pattern in prompt_injection_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                flags.append("prompt_injection")
                severity = "critical"
                reason = "Prompt injection attempt detected"
                action = "BLACKLIST"
                break
        
        # Bot-generated patterns
        bot_indicators = ["as an ai language model", "generated by chatgpt", "written by gpt"]
        for indicator in bot_indicators:
            if indicator in text.lower():
                flags.append("bot_generated")
                severity = "high"
                reason = "Resume appears to be AI-generated"
                action = "NEEDS_REVIEW"
                break

        # 2. Deep Analysis using existing ATSAgent (if available)
        ats_result = {}
        try:
            if ats_agent is None:
                try:
                    from skill_verification_agent.agents.ats import ATSEvidenceAgent
                    ats_agent = ATSEvidenceAgent(llm=None)
                except Exception as e:
                    logger.error(f"Lazy loading of ATSEvidenceAgent failed: {str(e)}")
                    pass
            
            if ats_agent:
                # Use extract_evidence instead of analyze if it matches the class
                if hasattr(ats_agent, 'extract_evidence'):
                    logger.info(f"[ATS] Triggering DEEP analysis for {request.resume_path or 'text'}")
                    import asyncio
                    ats_result = await asyncio.to_thread(
                        ats_agent.extract_evidence,
                        request.resume_path or "",
                        True, # deep_check
                        str(request.application_id)
                    )
                    logger.info(f"[ATS] Deep analysis complete. Status: {ats_result.get('status', 'OK')}")
                elif hasattr(ats_agent, 'analyze'):
                    ats_result = ats_agent.analyze(text)
        except Exception as e:
            logger.error(f"Deep ATS analysis failed: {str(e)}")
            ats_result = {"error": str(e), "status": "FAIL"}

        # Merge results
        if ats_result.get("final_action") == "BLACKLISTED":
            action = "BLACKLIST"
            reason = ats_result.get("reason", reason)
        elif ats_result.get("final_action") == "PENDING_HUMAN_REVIEW":
            action = "NEEDS_REVIEW"
            reason = ats_result.get("reason", reason)

        if action == "OK" and severity in ["high", "critical"]:
            action = "NEEDS_REVIEW"

        return ATSResponse(
            action=action,
            status=action,
            fraud_detected=action == "BLACKLIST",
            needs_review=action == "NEEDS_REVIEW",
            reason=reason or ats_result.get("human_review_reason"),
            severity=severity,
            flags=flags + ats_result.get("flags", []),
            analysis={
                "realtime_checks": {
                    "white_text_count": white_text_count,
                    "bot_detected": "bot_generated" in flags
                },
                "deep_analysis": ats_result
            },
            evidence=ats_result.get("evidence", {})
        )
    
    except Exception as e:
        logger.error(f"ATS analysis failed: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"ATS fraud detection failed: {str(e)}"
        )


@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "ats_fraud_detection",
        "agent_loaded": ats_agent is not None
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8004)